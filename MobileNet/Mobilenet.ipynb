{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc6YpNI1s0jn",
        "outputId": "2b8f32cf-d02b-4952-852d-aa57dd553e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ahmedxc4/skin-ds?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.25G/9.25G [01:37<00:00, 102MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/ahmedxc4/skin-ds/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"ahmedxc4/skin-ds\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_PATH = \"/root/.cache/kagglehub/datasets/ahmedxc4/skin-ds/versions/2\"\n",
        "\n",
        "TRAIN_PATH = os.path.join(BASE_PATH, \"train\")\n",
        "VAL_PATH   = os.path.join(BASE_PATH, \"val\")\n",
        "TEST_PATH  = os.path.join(BASE_PATH, \"test\")\n",
        "\n",
        "print(os.listdir(TRAIN_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v8tFrxCs5ZJ",
        "outputId": "596c681d-74e8-4683-c3bc-922df5638017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Basal cell carcinoma', 'Chickenpox', 'Benign keratosis-like lesions', 'Measles', 'Melanocytic nevi', 'Cowpox', 'Squamous cell carcinoma', 'Actinic keratoses', 'Healthy', 'Monkeypox', 'Dermatofibroma', 'Melanoma', 'HFMD', 'Vascular lesions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMG_SIZE = (224, 224)   # MobileNet standard input\n",
        "BATCH_SIZE = 32\n"
      ],
      "metadata": {
        "id": "TQ7Yxckht6PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "ckxLMgJdt9f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_data = val_test_datagen.flow_from_directory(\n",
        "    VAL_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_data = val_test_datagen.flow_from_directory(\n",
        "    TEST_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4MDZ_I-uDXz",
        "outputId": "9a82bbb5-6a60-4219-8a71-3812f6b9f01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 29322 images belonging to 14 classes.\n",
            "Found 3660 images belonging to 14 classes.\n",
            "Found 3674 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "base_model = MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False   # Freeze pretrained layers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrarqyB7uFss",
        "outputId": "d3a19421-61c7-489a-a4bf-2fd21c55c082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "output = Dense(train_data.num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n"
      ],
      "metadata": {
        "id": "m4T3CLFzuKHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "UmNAzNQJuN8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV1Xc7g2uQZC",
        "outputId": "cc20b22b-4d38-4e46-bd84-515773d526e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 742ms/step - accuracy: 0.6095 - loss: 1.1591 - val_accuracy: 0.6967 - val_loss: 0.8539\n",
            "Epoch 2/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 681ms/step - accuracy: 0.7040 - loss: 0.8198 - val_accuracy: 0.6992 - val_loss: 0.8317\n",
            "Epoch 3/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 675ms/step - accuracy: 0.7320 - loss: 0.7431 - val_accuracy: 0.6973 - val_loss: 0.8242\n",
            "Epoch 4/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 680ms/step - accuracy: 0.7384 - loss: 0.7214 - val_accuracy: 0.7183 - val_loss: 0.7805\n",
            "Epoch 5/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 681ms/step - accuracy: 0.7503 - loss: 0.6855 - val_accuracy: 0.7227 - val_loss: 0.7707\n",
            "Epoch 6/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 688ms/step - accuracy: 0.7591 - loss: 0.6729 - val_accuracy: 0.7134 - val_loss: 0.8106\n",
            "Epoch 7/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 691ms/step - accuracy: 0.7637 - loss: 0.6448 - val_accuracy: 0.7265 - val_loss: 0.7672\n",
            "Epoch 8/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 692ms/step - accuracy: 0.7742 - loss: 0.6203 - val_accuracy: 0.7268 - val_loss: 0.7680\n",
            "Epoch 9/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 683ms/step - accuracy: 0.7779 - loss: 0.6082 - val_accuracy: 0.7383 - val_loss: 0.7460\n",
            "Epoch 10/10\n",
            "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 677ms/step - accuracy: 0.7806 - loss: 0.5836 - val_accuracy: 0.7270 - val_loss: 0.7668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print(\"MobileNet Test Accuracy:\", round(test_accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl5SfljcuSvM",
        "outputId": "5f55a2ab-8788-4ebc-bdee-2c8cb3f02ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 410ms/step - accuracy: 0.6691 - loss: 1.0239\n",
            "MobileNet Test Accuracy: 73.65 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_true = test_data.classes\n",
        "y_pred = np.argmax(model.predict(test_data), axis=1)\n",
        "\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrE87oLLGny0",
        "outputId": "97faa5eb-a58c-445b-9b0b-48cc08f45937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 276ms/step\n",
            "[[  26   25   13    0    0    1    0    0    0   11    9    0    3    0]\n",
            " [  15  218   23    0    0    0    0    0    0   47   20    0    9    1]\n",
            " [  10   28  113    0    0    0    0    0    0   56   50    0    2    4]\n",
            " [   0    0    0   82    5    0    2    2    2    0    0   20    0    0]\n",
            " [   0    0    0    0   91    0    0    3    0    1    0    4    0    0]\n",
            " [   0    4    5    0    0    1    0    0    0   12    1    0    2    0]\n",
            " [   0    0    0    0    6    0  226    2    0    2    0    5    0    1]\n",
            " [   0    2    0    2    1    0   10  145    1    3    0    7    0    0]\n",
            " [   0    0    0    0    1    0   12    0   61    1    0    8    0    0]\n",
            " [   1   42   66    0    0    1    1    0    0 1097   77    0    3    0]\n",
            " [   7   19   41    0    0    0    0    0    0  137  243    0    3    3]\n",
            " [   0    0    0    2   19    0   14    9    5    5    2  370    0    0]\n",
            " [   4   17   12    0    0    0    0    0    0    4   11    0   16    0]\n",
            " [   0    1    1    0    0    0    0    0    0    6    1    0    0   17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.30      0.34        88\n",
            "           1       0.61      0.65      0.63       333\n",
            "           2       0.41      0.43      0.42       263\n",
            "           3       0.95      0.73      0.82       113\n",
            "           4       0.74      0.92      0.82        99\n",
            "           5       0.33      0.04      0.07        25\n",
            "           6       0.85      0.93      0.89       242\n",
            "           7       0.90      0.85      0.87       171\n",
            "           8       0.88      0.73      0.80        83\n",
            "           9       0.79      0.85      0.82      1288\n",
            "          10       0.59      0.54      0.56       453\n",
            "          11       0.89      0.87      0.88       426\n",
            "          12       0.42      0.25      0.31        64\n",
            "          13       0.65      0.65      0.65        26\n",
            "\n",
            "    accuracy                           0.74      3674\n",
            "   macro avg       0.68      0.62      0.64      3674\n",
            "weighted avg       0.73      0.74      0.73      3674\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ctjlTbdxG_th"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}